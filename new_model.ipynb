{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "import statsmodels.formula.api as smf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.342461\n",
      "         Iterations 17\n"
     ]
    }
   ],
   "source": [
    "#make array with : director_high+director_low+actor_1_high+actor_1_low+actor_2_high+actor_2_low+actor_3_high+actor_3_low\n",
    "predictors_actors = ['director_high','director_low','actor_1_high','actor_1_low','actor_2_high','actor_2_low','actor_3_high','actor_3_low']\n",
    "#action + biography + comedy + crime + documentary + drama + history + horror + music + musical + mystery + romance + sport + thriller + war + western\n",
    "predictors_genre = ['action','biography','comedy','crime','documentary','drama','history','horror','music','musical','mystery','romance','sport','thriller','war','western']\n",
    "#make logistic model predicting profit_binary from predictors_actors + predictors_genre\n",
    "logistic_model = smf.logit(formula = 'profit_binary ~ ' + ' + '.join(predictors_actors) + ' + ' + ' + '.join(predictors_genre), data = train).fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>profit_binary</td>  <th>  No. Observations:  </th>  <td>  2998</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  2976</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    21</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sun, 05 Mar 2023</td> <th>  Pseudo R-squ.:     </th>  <td>0.5039</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>23:35:31</td>     <th>  Log-Likelihood:    </th> <td> -1026.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -2069.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td> 0.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>     <td>   -0.0601</td> <td> 2.24e+06</td> <td>-2.68e-08</td> <td> 1.000</td> <td>-4.39e+06</td> <td> 4.39e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>director_high</th> <td>    0.7491</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>director_low</th>  <td>   -0.8092</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>actor_1_high</th>  <td>    0.3452</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>actor_1_low</th>   <td>   -0.4052</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>actor_2_high</th>  <td>    0.7462</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>actor_2_low</th>   <td>   -0.8062</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>actor_3_high</th>  <td>    1.1746</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>actor_3_low</th>   <td>   -1.2346</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>action</th>        <td>   -0.2639</td> <td>    0.156</td> <td>   -1.694</td> <td> 0.090</td> <td>   -0.569</td> <td>    0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>biography</th>     <td>   -0.1873</td> <td>    0.259</td> <td>   -0.723</td> <td> 0.470</td> <td>   -0.695</td> <td>    0.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>comedy</th>        <td>   -0.2164</td> <td>    0.147</td> <td>   -1.477</td> <td> 0.140</td> <td>   -0.504</td> <td>    0.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>crime</th>         <td>    0.0883</td> <td>    0.157</td> <td>    0.563</td> <td> 0.574</td> <td>   -0.219</td> <td>    0.396</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>documentary</th>   <td>    1.7499</td> <td>    0.618</td> <td>    2.834</td> <td> 0.005</td> <td>    0.540</td> <td>    2.960</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>drama</th>         <td>    0.0648</td> <td>    0.140</td> <td>    0.462</td> <td> 0.644</td> <td>   -0.210</td> <td>    0.340</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>history</th>       <td>    0.1649</td> <td>    0.315</td> <td>    0.523</td> <td> 0.601</td> <td>   -0.453</td> <td>    0.782</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horror</th>        <td>    0.5838</td> <td>    0.220</td> <td>    2.654</td> <td> 0.008</td> <td>    0.153</td> <td>    1.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>music</th>         <td>    0.0969</td> <td>    0.315</td> <td>    0.308</td> <td> 0.758</td> <td>   -0.520</td> <td>    0.714</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>musical</th>       <td>    0.1952</td> <td>    0.393</td> <td>    0.497</td> <td> 0.619</td> <td>   -0.575</td> <td>    0.966</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mystery</th>       <td>    0.0995</td> <td>    0.201</td> <td>    0.496</td> <td> 0.620</td> <td>   -0.294</td> <td>    0.493</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>romance</th>       <td>    0.1566</td> <td>    0.143</td> <td>    1.097</td> <td> 0.273</td> <td>   -0.123</td> <td>    0.436</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sport</th>         <td>   -0.1598</td> <td>    0.291</td> <td>   -0.550</td> <td> 0.582</td> <td>   -0.729</td> <td>    0.410</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>thriller</th>      <td>   -0.1020</td> <td>    0.159</td> <td>   -0.642</td> <td> 0.521</td> <td>   -0.414</td> <td>    0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>war</th>           <td>    0.1247</td> <td>    0.308</td> <td>    0.404</td> <td> 0.686</td> <td>   -0.480</td> <td>    0.729</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>western</th>       <td>   -0.3379</td> <td>    0.499</td> <td>   -0.678</td> <td> 0.498</td> <td>   -1.315</td> <td>    0.639</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:          profit_binary   No. Observations:                 2998\n",
       "Model:                          Logit   Df Residuals:                     2976\n",
       "Method:                           MLE   Df Model:                           21\n",
       "Date:                Sun, 05 Mar 2023   Pseudo R-squ.:                  0.5039\n",
       "Time:                        23:35:31   Log-Likelihood:                -1026.7\n",
       "converged:                       True   LL-Null:                       -2069.5\n",
       "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
       "=================================================================================\n",
       "                    coef    std err          z      P>|z|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "Intercept        -0.0601   2.24e+06  -2.68e-08      1.000   -4.39e+06    4.39e+06\n",
       "director_high     0.7491        nan        nan        nan         nan         nan\n",
       "director_low     -0.8092        nan        nan        nan         nan         nan\n",
       "actor_1_high      0.3452        nan        nan        nan         nan         nan\n",
       "actor_1_low      -0.4052        nan        nan        nan         nan         nan\n",
       "actor_2_high      0.7462        nan        nan        nan         nan         nan\n",
       "actor_2_low      -0.8062        nan        nan        nan         nan         nan\n",
       "actor_3_high      1.1746        nan        nan        nan         nan         nan\n",
       "actor_3_low      -1.2346        nan        nan        nan         nan         nan\n",
       "action           -0.2639      0.156     -1.694      0.090      -0.569       0.041\n",
       "biography        -0.1873      0.259     -0.723      0.470      -0.695       0.321\n",
       "comedy           -0.2164      0.147     -1.477      0.140      -0.504       0.071\n",
       "crime             0.0883      0.157      0.563      0.574      -0.219       0.396\n",
       "documentary       1.7499      0.618      2.834      0.005       0.540       2.960\n",
       "drama             0.0648      0.140      0.462      0.644      -0.210       0.340\n",
       "history           0.1649      0.315      0.523      0.601      -0.453       0.782\n",
       "horror            0.5838      0.220      2.654      0.008       0.153       1.015\n",
       "music             0.0969      0.315      0.308      0.758      -0.520       0.714\n",
       "musical           0.1952      0.393      0.497      0.619      -0.575       0.966\n",
       "mystery           0.0995      0.201      0.496      0.620      -0.294       0.493\n",
       "romance           0.1566      0.143      1.097      0.273      -0.123       0.436\n",
       "sport            -0.1598      0.291     -0.550      0.582      -0.729       0.410\n",
       "thriller         -0.1020      0.159     -0.642      0.521      -0.414       0.209\n",
       "war               0.1247      0.308      0.404      0.686      -0.480       0.729\n",
       "western          -0.3379      0.499     -0.678      0.498      -1.315       0.639\n",
       "=================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summary\n",
    "logistic_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred on test\n",
    "test['pred'] = logistic_model.predict(test)\n",
    "\n",
    "#make binary prediction\n",
    "test['pred_binary'] = np.where(test['pred'] > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "#accuracy on test\n",
    "accuracy = sum(test['pred_binary'] == test['profit_binary'])/len(test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
