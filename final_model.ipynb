{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.339020\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yasmeen\\AppData\\Roaming\\Python\\Python310\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "standard_predictors = ['duration', 'director_facebook_likes', 'actor_3_facebook_likes', 'actor_1_facebook_likes', 'cast_total_facebook_likes', 'facenumber_in_poster', 'actor_2_facebook_likes', 'aspect_ratio']\n",
    "predictors_actors = ['director_high', 'director_low', 'actor_1_high', 'actor_1_low', 'actor_2_high', 'actor_2_low', 'actor_3_high', 'actor_3_low']\n",
    "predictors_genre = ['action', 'biography', 'comedy', 'crime', 'documentary', 'drama', 'history', 'horror', 'music', 'musical', 'mystery', 'romance', 'sport', 'thriller', 'war', 'western']\n",
    "logistic_model = smf.logit(formula='profit_binary ~ ' + ' + '.join(predictors_actors) + ' + ' + ' + '.join(predictors_genre) + ' + ' + ' + '.join(standard_predictors), data=train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>profit_binary</td>  <th>  No. Observations:  </th>  <td>  2998</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  2969</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    28</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 08 Mar 2023</td> <th>  Pseudo R-squ.:     </th>  <td>0.5089</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>21:46:47</td>     <th>  Log-Likelihood:    </th> <td> -1016.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>False</td>      <th>  LL-Null:           </th> <td> -2069.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td> 0.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                 <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                 <td>    0.6595</td> <td> 2.28e+06</td> <td> 2.89e-07</td> <td> 1.000</td> <td>-4.47e+06</td> <td> 4.47e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>director_high</th>             <td>    1.1246</td> <td> 2.45e+06</td> <td> 4.58e-07</td> <td> 1.000</td> <td>-4.81e+06</td> <td> 4.81e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>director_low</th>              <td>   -0.4651</td> <td> 2.47e+06</td> <td>-1.88e-07</td> <td> 1.000</td> <td>-4.85e+06</td> <td> 4.85e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>actor_1_high</th>              <td>    0.7311</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>actor_1_low</th>               <td>   -0.0717</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>actor_2_high</th>              <td>    1.1343</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>actor_2_low</th>               <td>   -0.4749</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>actor_3_high</th>              <td>    1.5421</td> <td> 2.66e+06</td> <td>  5.8e-07</td> <td> 1.000</td> <td>-5.21e+06</td> <td> 5.21e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>actor_3_low</th>               <td>   -0.8826</td> <td> 2.66e+06</td> <td>-3.32e-07</td> <td> 1.000</td> <td>-5.21e+06</td> <td> 5.21e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>action</th>                    <td>   -0.1509</td> <td>    0.160</td> <td>   -0.945</td> <td> 0.345</td> <td>   -0.464</td> <td>    0.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>biography</th>                 <td>   -0.1121</td> <td>    0.260</td> <td>   -0.431</td> <td> 0.667</td> <td>   -0.622</td> <td>    0.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>comedy</th>                    <td>   -0.3640</td> <td>    0.157</td> <td>   -2.324</td> <td> 0.020</td> <td>   -0.671</td> <td>   -0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>crime</th>                     <td>    0.0624</td> <td>    0.158</td> <td>    0.395</td> <td> 0.693</td> <td>   -0.247</td> <td>    0.372</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>documentary</th>               <td>    1.4477</td> <td>    0.625</td> <td>    2.318</td> <td> 0.020</td> <td>    0.224</td> <td>    2.672</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>drama</th>                     <td>    0.0960</td> <td>    0.142</td> <td>    0.676</td> <td> 0.499</td> <td>   -0.182</td> <td>    0.374</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>history</th>                   <td>    0.2174</td> <td>    0.319</td> <td>    0.681</td> <td> 0.496</td> <td>   -0.408</td> <td>    0.843</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horror</th>                    <td>    0.5311</td> <td>    0.223</td> <td>    2.382</td> <td> 0.017</td> <td>    0.094</td> <td>    0.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>music</th>                     <td>    0.1037</td> <td>    0.317</td> <td>    0.327</td> <td> 0.744</td> <td>   -0.518</td> <td>    0.725</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>musical</th>                   <td>    0.1334</td> <td>    0.402</td> <td>    0.332</td> <td> 0.740</td> <td>   -0.654</td> <td>    0.921</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mystery</th>                   <td>    0.1460</td> <td>    0.203</td> <td>    0.721</td> <td> 0.471</td> <td>   -0.251</td> <td>    0.543</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>romance</th>                   <td>    0.1529</td> <td>    0.144</td> <td>    1.059</td> <td> 0.290</td> <td>   -0.130</td> <td>    0.436</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sport</th>                     <td>   -0.1413</td> <td>    0.293</td> <td>   -0.482</td> <td> 0.630</td> <td>   -0.716</td> <td>    0.433</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>thriller</th>                  <td>   -0.0832</td> <td>    0.160</td> <td>   -0.519</td> <td> 0.604</td> <td>   -0.397</td> <td>    0.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>war</th>                       <td>    0.1714</td> <td>    0.311</td> <td>    0.551</td> <td> 0.581</td> <td>   -0.438</td> <td>    0.781</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>western</th>                   <td>   -0.2650</td> <td>    0.511</td> <td>   -0.519</td> <td> 0.604</td> <td>   -1.266</td> <td>    0.736</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>duration</th>                  <td>   -0.0050</td> <td>    0.003</td> <td>   -1.560</td> <td> 0.119</td> <td>   -0.011</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>director_facebook_likes</th>   <td>-4.806e-06</td> <td> 1.86e-05</td> <td>   -0.259</td> <td> 0.796</td> <td>-4.12e-05</td> <td> 3.16e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>actor_3_facebook_likes</th>    <td> 7.062e-06</td> <td>  7.9e-05</td> <td>    0.089</td> <td> 0.929</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>actor_1_facebook_likes</th>    <td> 2.081e-05</td> <td> 4.69e-05</td> <td>    0.444</td> <td> 0.657</td> <td> -7.1e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cast_total_facebook_likes</th> <td>-2.421e-05</td> <td> 4.68e-05</td> <td>   -0.517</td> <td> 0.605</td> <td>   -0.000</td> <td> 6.75e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>facenumber_in_poster</th>      <td>   -0.0094</td> <td>    0.028</td> <td>   -0.337</td> <td> 0.736</td> <td>   -0.064</td> <td>    0.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>actor_2_facebook_likes</th>    <td> 1.521e-05</td> <td> 4.91e-05</td> <td>    0.310</td> <td> 0.757</td> <td> -8.1e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aspect_ratio</th>              <td>   -0.7082</td> <td>    0.236</td> <td>   -3.006</td> <td> 0.003</td> <td>   -1.170</td> <td>   -0.246</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:          profit_binary   No. Observations:                 2998\n",
       "Model:                          Logit   Df Residuals:                     2969\n",
       "Method:                           MLE   Df Model:                           28\n",
       "Date:                Wed, 08 Mar 2023   Pseudo R-squ.:                  0.5089\n",
       "Time:                        21:46:47   Log-Likelihood:                -1016.4\n",
       "converged:                      False   LL-Null:                       -2069.5\n",
       "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
       "=============================================================================================\n",
       "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------\n",
       "Intercept                     0.6595   2.28e+06   2.89e-07      1.000   -4.47e+06    4.47e+06\n",
       "director_high                 1.1246   2.45e+06   4.58e-07      1.000   -4.81e+06    4.81e+06\n",
       "director_low                 -0.4651   2.47e+06  -1.88e-07      1.000   -4.85e+06    4.85e+06\n",
       "actor_1_high                  0.7311        nan        nan        nan         nan         nan\n",
       "actor_1_low                  -0.0717        nan        nan        nan         nan         nan\n",
       "actor_2_high                  1.1343        nan        nan        nan         nan         nan\n",
       "actor_2_low                  -0.4749        nan        nan        nan         nan         nan\n",
       "actor_3_high                  1.5421   2.66e+06    5.8e-07      1.000   -5.21e+06    5.21e+06\n",
       "actor_3_low                  -0.8826   2.66e+06  -3.32e-07      1.000   -5.21e+06    5.21e+06\n",
       "action                       -0.1509      0.160     -0.945      0.345      -0.464       0.162\n",
       "biography                    -0.1121      0.260     -0.431      0.667      -0.622       0.398\n",
       "comedy                       -0.3640      0.157     -2.324      0.020      -0.671      -0.057\n",
       "crime                         0.0624      0.158      0.395      0.693      -0.247       0.372\n",
       "documentary                   1.4477      0.625      2.318      0.020       0.224       2.672\n",
       "drama                         0.0960      0.142      0.676      0.499      -0.182       0.374\n",
       "history                       0.2174      0.319      0.681      0.496      -0.408       0.843\n",
       "horror                        0.5311      0.223      2.382      0.017       0.094       0.968\n",
       "music                         0.1037      0.317      0.327      0.744      -0.518       0.725\n",
       "musical                       0.1334      0.402      0.332      0.740      -0.654       0.921\n",
       "mystery                       0.1460      0.203      0.721      0.471      -0.251       0.543\n",
       "romance                       0.1529      0.144      1.059      0.290      -0.130       0.436\n",
       "sport                        -0.1413      0.293     -0.482      0.630      -0.716       0.433\n",
       "thriller                     -0.0832      0.160     -0.519      0.604      -0.397       0.231\n",
       "war                           0.1714      0.311      0.551      0.581      -0.438       0.781\n",
       "western                      -0.2650      0.511     -0.519      0.604      -1.266       0.736\n",
       "duration                     -0.0050      0.003     -1.560      0.119      -0.011       0.001\n",
       "director_facebook_likes   -4.806e-06   1.86e-05     -0.259      0.796   -4.12e-05    3.16e-05\n",
       "actor_3_facebook_likes     7.062e-06    7.9e-05      0.089      0.929      -0.000       0.000\n",
       "actor_1_facebook_likes     2.081e-05   4.69e-05      0.444      0.657    -7.1e-05       0.000\n",
       "cast_total_facebook_likes -2.421e-05   4.68e-05     -0.517      0.605      -0.000    6.75e-05\n",
       "facenumber_in_poster         -0.0094      0.028     -0.337      0.736      -0.064       0.045\n",
       "actor_2_facebook_likes     1.521e-05   4.91e-05      0.310      0.757    -8.1e-05       0.000\n",
       "aspect_ratio                 -0.7082      0.236     -3.006      0.003      -1.170      -0.246\n",
       "=============================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summary\n",
    "logistic_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge and Lasso"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
